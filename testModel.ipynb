{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscale thumbnails to 360p for training\n",
    "img_size = (480, 360)\n",
    "batch_size = 128\n",
    "epochs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(path):\n",
    "\timg = Image.open(path, 'r').convert('RGB').resize(img_size)\n",
    "\t# Convert colors from 0-255 to 0-1\n",
    "\treturn np.asarray(img) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI tries to match target values given source values\n",
    "source = []\n",
    "target = []\n",
    "\n",
    "# Import thumbnails from dataset/ folder\n",
    "for img in os.listdir('dataset'):\n",
    "\tsource.append(loadImage(f'dataset/{img}'))\n",
    "\tviews, subs = img[12:-4].split(\"_\")\n",
    "\ttarget.append(int(views) / int(subs))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "source = np.array(source)\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(source, target, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "\t[\n",
    "\t\t# Input has 3 dimensions: height x width x 3 color channels (RGB)\n",
    "\t\tkeras.Input(shape=(img_size[1], img_size[0], 3)),\n",
    "\n",
    "\t\t# Try to learn small-scale details + shrink input\n",
    "\t\tkeras.layers.Conv2D(filters=8, kernel_size=3, strides=2, padding='Same', activation='relu'),\n",
    "\t\tkeras.layers.Conv2D(filters=16, kernel_size=3, strides=2, padding='Same', activation='relu'),\n",
    "\t\tkeras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "\n",
    "\t\t# Try to learn medium-scale details + shrink input\n",
    "\t\tkeras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='Same', activation='relu'),\n",
    "\t\tkeras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='Same', activation='relu'),\n",
    "\t\tkeras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "\n",
    "\t\t# Try to learn large-scale details + shrink input\n",
    "\t\tkeras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='Same', activation='relu'),\n",
    "\t\tkeras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='Same', activation='relu'),\n",
    "\t\tkeras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "\n",
    "\t\t# Convert from 3D to 1D\n",
    "\t\tkeras.layers.Flatten(),\n",
    "\n",
    "\t\t# Hope neuron layers do something useful, may blow up your GPU\n",
    "\t\tkeras.layers.Dense(16384, activation='relu'), # idk whether to activate this\n",
    "\t\tkeras.layers.Dense(4096), # idk whether to activate this\n",
    "\n",
    "\t\t# Output has 1 dimension: view count / subscriber count\n",
    "\t\tkeras.layers.Dense(1)\n",
    "\t]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'mae' seems slightly better than 'mse'\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='mae')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "\tbatch_size=batch_size,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=(x_valid, y_valid),\n",
    "\tsteps_per_epoch=x_train.shape[0] // batch_size # num_samples / batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"validation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_valid).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_results = 32\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(num_results)\n",
    "rects1 = ax.bar(x - width / 2, y_valid[:num_results], width, label='Actual')\n",
    "rects2 = ax.bar(x + width / 2, preds[:num_results], width, label='Predicted')\n",
    "ax.legend()\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "fig.tight_layout()\n",
    "plt.title(\"Actual vs predicted views\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88076a93485f247efb60c9d00611d55633c59f1fed461cddd11c3c36f6a72202"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
